{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pyspark3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1V5MDnU8ACg8Mgg8iZW1D46dQ-iNWc0BO",
      "authorship_tag": "ABX9TyMJlWA473Cs0Q9jae1YBRgC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MarianaDuartee/Pyspark/blob/main/Pyspark3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SW2DjTCKyz9q",
        "outputId": "3165fde1-35de-40f7-8bb2-6df6265d834e"
      },
      "source": [
        "! pip install pyspark"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.2.0.tar.gz (281.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.3 MB 35 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.2\n",
            "  Downloading py4j-0.10.9.2-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[K     |████████████████████████████████| 198 kB 62.0 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.2.0-py2.py3-none-any.whl size=281805912 sha256=ce2aaf46bcd614e7033c75c50fba3fce6a2644b8414180eeb930a04fe3853d41\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/de/d2/9be5d59d7331c6c2a7c1b6d1a4f463ce107332b1ecd4e80718\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.2 pyspark-3.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1y_bD10y6Lv"
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "import pyspark.sql.functions as F"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wlmmTcAy7-f"
      },
      "source": [
        "spark = (SparkSession.builder\n",
        "         .master(\"local\")\n",
        "         .appName(\"aprendendo-dataframes\")\n",
        "         .config(\"spark.ui.port\",\"4050\")\n",
        "         .getOrCreate())"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dvGtwzHy-6f"
      },
      "source": [
        "df = (spark\n",
        "      .read\n",
        "      .format(\"csv\")\n",
        "      .option(\"header\",\"true\")\n",
        "      .option(\"inferschema\",\"true\")\n",
        "      .option(\"delimiter\",\";\")\n",
        "      .load(\"/content/drive/MyDrive/DataSets/arquivo_geral.csv\")\n",
        "      )\n",
        "\n",
        "df.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ahEEG0ulzAhu",
        "outputId": "1cd79175-37cd-4c74-b77d-5c0b0083ef16"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJRrKCSszLmd"
      },
      "source": [
        "\n",
        "---\n",
        "\n",
        "#Outras Funções - Pyspark\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4f3MFCz8zbT5"
      },
      "source": [
        "#WHEN - OTHERWISE\n",
        "\n",
        "* Condições para criar ou não novas colunas\n",
        "\n",
        "* Parecido com IF | ELSE, onde IF = WHEN e ELSE = OTHERWISE\n",
        "\n",
        "* Exemplo: Criar uma nova coluna com as seguintes condições:\n",
        "\n",
        "> Se o numero de casos novos for maior que zero, acrescentar o texto \"Tem casos Novos\"\n",
        "\n",
        "> Se o numero de casos novos não for maior que zero, acrescentar o texto \"Sem casos Novos\"\n",
        "\n",
        "1. O código abaixo cria um novo dataframe (df2) com o dataframe original (df)\n",
        "2. Além das colunas presentes no df original, cria uma nova coluna chamada status (withColumn(\"status\") ...\n",
        "3. Os valores passados para essa nova coluna possuem condições especificas (**F.when**(condição , valor passado caso a condição seja True).**otherwise**(valor passado caso a condição seja False)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1wLY_agzW7c"
      },
      "source": [
        "df2 = (df.withColumn(\"status\",F.when(F.col(\"casosNovos\")>0,\"Tem Casos Novos\")\n",
        "       .otherwise(\"Sem casos novos\")))\n",
        "\n",
        "df2.show(100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SC1k59Ac2QH2"
      },
      "source": [
        "#Concat\n",
        "\n",
        "* F.concat (coluna1,F.lit('texto a ser concatenado')\n",
        "\n",
        "* Exemplo: Concatenando a quantidade de casos novos com o status"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5aeKBgID1700"
      },
      "source": [
        "df3 = (df.withColumn(\"status\", \n",
        "                     F.when(F.col('casosNovos') > 0, F.concat(df.casosNovos,F.lit(\" casos novos\")))\n",
        "                     .otherwise(\"Não tem casos novos.\")\n",
        "                     ))\n",
        "\n",
        "df3.select(F.col('status'),F.col('casosNovos'),F.col('data')).filter(F.col('status') != 'Não tem casos novos.').show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDSZd0zc5PMN"
      },
      "source": [
        "#Substring \n",
        "* Exige 3 parametros\n",
        "\n",
        "* Primeiro : A propria string que esta percorrendo\n",
        "\n",
        "* Segundo : Posição inicial que quer pegar da string\n",
        "\n",
        "* Terceiro: Tamanho da substring que quer pegar\n",
        "\n",
        "* F.substring('valor da string', 'Posição inicial', 'Tamanho total')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLWp0IA-4pT9"
      },
      "source": [
        "* Exemplo: Criar colunas com Dia/Mês/Ano para ficar mais organizado no Dataframe\n",
        "\n",
        "> Isso é feito com a utilização da withColumn que cria uma nova coluna junto com a substring \n",
        "\n",
        "> A substring mostra uma parte da string de acordo com os parâmetros escolhidos "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTevLZFN5IY8"
      },
      "source": [
        "df3 = (df.withColumn(\"Dia\", F.substring(df.data,9,2))\n",
        "         .withColumn(\"Mês\",F.substring(df.data,6,2))\n",
        "         .withColumn(\"Ano\",F.substring(df.data,1,4)))\n",
        "\n",
        "df3.select(F.col('data'),F.col('Dia'),F.col(\"Mês\"),F.col(\"Ano\")).show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
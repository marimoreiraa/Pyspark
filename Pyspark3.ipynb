{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pyspark3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1V5MDnU8ACg8Mgg8iZW1D46dQ-iNWc0BO",
      "authorship_tag": "ABX9TyPlyIftegbf52IuaK8PmZOW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MarianaDuartee/Pyspark/blob/main/Pyspark3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SW2DjTCKyz9q",
        "outputId": "3165fde1-35de-40f7-8bb2-6df6265d834e"
      },
      "source": [
        "! pip install pyspark"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.2.0.tar.gz (281.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.3 MB 35 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.2\n",
            "  Downloading py4j-0.10.9.2-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[K     |████████████████████████████████| 198 kB 62.0 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.2.0-py2.py3-none-any.whl size=281805912 sha256=ce2aaf46bcd614e7033c75c50fba3fce6a2644b8414180eeb930a04fe3853d41\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/de/d2/9be5d59d7331c6c2a7c1b6d1a4f463ce107332b1ecd4e80718\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.2 pyspark-3.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1y_bD10y6Lv"
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "import pyspark.sql.functions as F"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wlmmTcAy7-f"
      },
      "source": [
        "spark = (SparkSession.builder\n",
        "         .master(\"local\")\n",
        "         .appName(\"aprendendo-dataframes\")\n",
        "         .config(\"spark.ui.port\",\"4050\")\n",
        "         .getOrCreate())"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dvGtwzHy-6f"
      },
      "source": [
        "df = (spark\n",
        "      .read\n",
        "      .format(\"csv\")\n",
        "      .option(\"header\",\"true\")\n",
        "      .option(\"inferschema\",\"true\")\n",
        "      .option(\"delimiter\",\";\")\n",
        "      .load(\"/content/drive/MyDrive/DataSets/arquivo_geral.csv\")\n",
        "      )\n",
        "\n",
        "df.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ahEEG0ulzAhu",
        "outputId": "1cd79175-37cd-4c74-b77d-5c0b0083ef16"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJRrKCSszLmd"
      },
      "source": [
        "\n",
        "---\n",
        "\n",
        "#Outras Funções - Pyspark\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4f3MFCz8zbT5"
      },
      "source": [
        "#WHEN - OTHERWISE\n",
        "\n",
        "* Condições para criar ou não novas colunas\n",
        "\n",
        "* Parecido com IF | ELSE, onde IF = WHEN e ELSE = OTHERWISE\n",
        "\n",
        "* Exemplo: Criar uma nova coluna com as seguintes condições:\n",
        "\n",
        "> Se o numero de casos novos for maior que zero, acrescentar o texto \"Tem casos Novos\"\n",
        "\n",
        "> Se o numero de casos novos não for maior que zero, acrescentar o texto \"Sem casos Novos\"\n",
        "\n",
        "1. O código abaixo cria um novo dataframe (df2) com o dataframe original (df)\n",
        "2. Além das colunas presentes no df original, cria uma nova coluna chamada status (withColumn(\"status\") ...\n",
        "3. Os valores passados para essa nova coluna possuem condições especificas (**F.when**(condição , valor passado caso a condição seja True).**otherwise**(valor passado caso a condição seja False)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1wLY_agzW7c"
      },
      "source": [
        "df2 = (df.withColumn(\"status\",F.when(F.col(\"casosNovos\")>0,\"Tem Casos Novos\")\n",
        "       .otherwise(\"Sem casos novos\")))\n",
        "\n",
        "df2.show(100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SC1k59Ac2QH2"
      },
      "source": [
        "#Concat\n",
        "\n",
        "* F.concat (coluna1,F.lit('texto a ser concatenado')\n",
        "\n",
        "* Exemplo: Concatenando a quantidade de casos novos com o status"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5aeKBgID1700"
      },
      "source": [
        "df3 = (df.withColumn(\"status\", \n",
        "                     F.when(F.col('casosNovos') > 0, F.concat(df.casosNovos,F.lit(\" casos novos\")))\n",
        "                     .otherwise(\"Não tem casos novos.\")\n",
        "                     ))\n",
        "\n",
        "df3.select(F.col('status'),F.col('casosNovos'),F.col('data')).filter(F.col('status') != 'Não tem casos novos.').show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDSZd0zc5PMN"
      },
      "source": [
        "#Substring \n",
        "* Exige 3 parametros\n",
        "\n",
        "* Primeiro : A propria string que esta percorrendo\n",
        "\n",
        "* Segundo : Posição inicial que quer pegar da string\n",
        "\n",
        "* Terceiro: Tamanho da substring que quer pegar\n",
        "\n",
        "* F.substring('valor da string', 'Posição inicial', 'Tamanho total')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLWp0IA-4pT9"
      },
      "source": [
        "* Exemplo: Criar colunas com Dia/Mês/Ano para ficar mais organizado no Dataframe\n",
        "\n",
        "> Isso é feito com a utilização da withColumn que cria uma nova coluna junto com a substring \n",
        "\n",
        "> A substring mostra uma parte da string de acordo com os parâmetros escolhidos "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTevLZFN5IY8"
      },
      "source": [
        "df3 = (df.withColumn(\"Dia\", F.substring(df.data,9,2))\n",
        "         .withColumn(\"Mês\",F.substring(df.data,6,2))\n",
        "         .withColumn(\"Ano\",F.substring(df.data,1,4)))\n",
        "\n",
        "df3.select(F.col('data'),F.col('Dia'),F.col(\"Mês\"),F.col(\"Ano\")).show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFV93gofN1N3"
      },
      "source": [
        "#StructType\n",
        "\n",
        "* Definir a Estrutura do DataFrame\n",
        "\n",
        "* Definir quais as colunas e tipos de dados estão vindo do DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKYDyo7uRLSF"
      },
      "source": [
        "from pyspark.sql.types import StructType, StructField, StringType, IntegerType"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WAt7bHI4QJ4O",
        "outputId": "2954f47c-bb6e-488e-8653-ec61549afa4e"
      },
      "source": [
        "dados = [\n",
        "         (\"Mariana\",\"Duarte\",\"Moreira\",\"12345\",\"F\",3500),\n",
        "         (\"João\",\"da\",\"Silva\",\"87663\",\"M\",2500),\n",
        "         (\"Priscila\",\"dos\",\"Santos\",\"12879\",\"F\",1500),\n",
        "         (\"Carla\",\"Paixão\",\"dos Anjos\",\"97856\",\"F\",2700),\n",
        "         (\"Edson\",\"de\",\"Almeida\",\"44023\",\"F\",2200)\n",
        "]\n",
        "\n",
        "schema = (\n",
        "    StructType([\n",
        "                StructField(\"primeiro_nome\",StringType(),True),\n",
        "                StructField(\"nome_do_meio\",StringType(),True),\n",
        "                StructField(\"ultimo_nome\",StringType(),True),\n",
        "                StructField(\"codigo\",StringType(),True),\n",
        "                StructField(\"genero\",StringType(),True),\n",
        "                StructField(\"salario\",IntegerType(),True)\n",
        "    ])\n",
        ")\n",
        "\n",
        "df = spark.createDataFrame(data=dados,schema=schema)\n",
        "\n",
        "df.show()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+------------+-----------+------+------+-------+\n",
            "|primeiro_nome|nome_do_meio|ultimo_nome|codigo|genero|salario|\n",
            "+-------------+------------+-----------+------+------+-------+\n",
            "|      Mariana|      Duarte|    Moreira| 12345|     F|   3500|\n",
            "|         João|          da|      Silva| 87663|     M|   2500|\n",
            "|     Priscila|         dos|     Santos| 12879|     F|   1500|\n",
            "|        Carla|      Paixão|  dos Anjos| 97856|     F|   2700|\n",
            "|        Edson|          de|    Almeida| 44023|     F|   2200|\n",
            "+-------------+------------+-----------+------+------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jedM8y6VTZDY",
        "outputId": "3d6c551b-e2f6-4f41-eea6-8863765610eb"
      },
      "source": [
        "df.printSchema()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- primeiro_nome: string (nullable = true)\n",
            " |-- nome_do_meio: string (nullable = true)\n",
            " |-- ultimo_nome: string (nullable = true)\n",
            " |-- codigo: string (nullable = true)\n",
            " |-- genero: string (nullable = true)\n",
            " |-- salario: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qC2b0_uUVpp1",
        "outputId": "fc8370e9-1875-413a-d6f0-ad6747524b20"
      },
      "source": [
        "dados = [\n",
        "         ((\"João\", \"da\", \"Silva\"), \"12345\", \"M\", 1000),\n",
        "         ((\"Priscila\", \"dos\", \"Santos\"), \"87663\", \"F\", 2200),\n",
        "         ((\"Carla\", \"Pereira\", \"Costa\"), \"12697\", \"F\", 3800),\n",
        "         ((\"Edson\", \"Paixão\", \"dos Anjos\"), \"44023\", \"M\", 1500),\n",
        "         ((\"Stella\", \"de\", \"Almeida\"), \"110001\", \"F\", 1560)\n",
        "]\n",
        "\n",
        "schema = StructType([\n",
        "        StructField(\"nome\", StructType([\n",
        "             StructField(\"primeiro_nome\", StringType(), True),\n",
        "             StructField(\"nome_do_meio\", StringType(), True),\n",
        "             StructField(\"ultimo_nome\", StringType(), True) \n",
        "        ])),\n",
        "        StructField(\"codigo\", StringType(), True),\n",
        "        StructField(\"genero\", StringType(), True),\n",
        "        StructField(\"salario\", IntegerType(), True)\n",
        "])\n",
        "\n",
        "df1 = spark.createDataFrame(data=dados, schema=schema)\n",
        "df1.printSchema()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- nome: struct (nullable = true)\n",
            " |    |-- primeiro_nome: string (nullable = true)\n",
            " |    |-- nome_do_meio: string (nullable = true)\n",
            " |    |-- ultimo_nome: string (nullable = true)\n",
            " |-- codigo: string (nullable = true)\n",
            " |-- genero: string (nullable = true)\n",
            " |-- salario: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wqc3UsZ8VsXN",
        "outputId": "08a44bc8-2bc3-4965-ac68-638e65a4ca0a"
      },
      "source": [
        "df1.show()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+------+------+-------+\n",
            "|                nome|codigo|genero|salario|\n",
            "+--------------------+------+------+-------+\n",
            "|   {João, da, Silva}| 12345|     M|   1000|\n",
            "|{Priscila, dos, S...| 87663|     F|   2200|\n",
            "|{Carla, Pereira, ...| 12697|     F|   3800|\n",
            "|{Edson, Paixão, d...| 44023|     M|   1500|\n",
            "|{Stella, de, Alme...|110001|     F|   1560|\n",
            "+--------------------+------+------+-------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}